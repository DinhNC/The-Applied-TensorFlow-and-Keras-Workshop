{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magic Commands\n",
    "Magic commands (those that start with `%`) are commands that modify a configuration of Jupyter Notebooks. A number of magic commands are available by default (see list [here](http://ipython.readthedocs.io/en/stable/interactive/magics.html))--and many more can be added with extensions. The magic command added in this section allows `matplotlib` to display our plots directly on the browser instead of having to save them on a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 8: Re-training a model dynamically\n",
    "In this activity, we re-train our model every time new data is available.\n",
    "\n",
    "First, we start by importing `cryptonic`. Cryptonic is a simple software application developed for this course that implements all the steps up to this section using Python classes and modules. Consider Cryptonic a template on how you could develop similar applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptonic import Model\n",
    "import cryptonic.models.normalizations as normalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Real-time Data\n",
    "Throughout this project we have been using data originally provided by Yahoo finance API. We have created an interface for collecting both real-time and historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is designed to work with daily data. Let's go ahead and collect historic daily data from Yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker =  yf.Ticker(\"BTC-USD\")\n",
    "historic_data = ticker.history(period='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_data = historic_data.rename(columns={'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'})\n",
    "historic_data.index.names = ['date']\n",
    "historic_data = historic_data[['open','high', 'low', 'close', 'volume']]\n",
    "historic_data = historic_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.86</td>\n",
       "      <td>468.17</td>\n",
       "      <td>452.42</td>\n",
       "      <td>457.33</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.86</td>\n",
       "      <td>456.86</td>\n",
       "      <td>413.10</td>\n",
       "      <td>424.44</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.10</td>\n",
       "      <td>427.83</td>\n",
       "      <td>384.53</td>\n",
       "      <td>394.80</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open    high     low   close    volume\n",
       "0 2014-09-17  465.86  468.17  452.42  457.33  21056800\n",
       "1 2014-09-18  456.86  456.86  413.10  424.44  34483200\n",
       "2 2014-09-19  424.10  427.83  384.53  394.80  37919700"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historic_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains practically the same variables from our earlier dataset. However, much of the data comes from an earlier period. Recent Bitcoin prices have gained a lot of volatility if compared to the prices of a few years ago. Before using this data in our model, let's make sure to filter it to dates after January 1, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Using the Pandas API, filter the dataframe\n",
    "#  for observations from 2017 only. \n",
    "# \n",
    "#  Hint: use the `date` column / variable.\n",
    "#\n",
    "\n",
    "start_date = '01-01-2019'\n",
    "end_date = '12-02-2020'\n",
    "mask = ((historic_data['date'] > start_date) & (historic_data['date']<= end_date))\n",
    "model_data = historic_data[mask]\n",
    "model_data = model_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Model()` Class\n",
    "We have also created the class `Model()` which compiles all the code we have written so far. We will use that class to build, train, and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model(data=model_data,\n",
    "          variable='close',\n",
    "          predicted_period_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1dd2add1978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0012\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 7.6650e-04\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 5.6529e-04\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 4.2971e-04\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.3069e-04\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.5589e-04\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.9849e-04\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.5410e-04\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 1.1965e-04\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 9.2854e-05\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 7.2012e-05\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 5.5797e-05\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 4.3179e-05\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.3354e-05\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.5695e-05\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 20ms/sample - loss: 1.9717e-05\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.5047e-05\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.1400e-05\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 8.5582e-06\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 6.3534e-06\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 4.6549e-06\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 3.3590e-06\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.3827e-06\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 1.6581e-06\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.1300e-06\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 7.5258e-07\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 4.8896e-07\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.0931e-07\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.9012e-07\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.1332e-07\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 6.5354e-08\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.6384e-08\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.9505e-08\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.0048e-08\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 5.0132e-09\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.8907e-09\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 6.5940e-09\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 6.2543e-08\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 7.1263e-07\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 4.5824e-06\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 8.2001e-06\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 9.4431e-06\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 8.5188e-06\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 4.8176e-06\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 20ms/sample - loss: 2.6662e-06\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 1.4584e-06\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 9.4840e-07\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 7.0226e-07\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 6.2755e-07\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 6.4763e-07\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 7.8828e-07\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.0754e-06\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.6387e-06\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 2.5554e-06\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 20ms/sample - loss: 3.8986e-06\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 5.0280e-06\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 5.4411e-06\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 20ms/sample - loss: 4.6433e-06\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 3.6974e-06\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.8175e-06\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 2.6272e-06\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 3.1886e-06\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.9250e-06\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.2591e-06\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.6056e-06\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 2.1402e-06\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 2.1490e-06\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.3324e-06\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 2.7942e-06\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 3.2267e-06\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 3.6888e-06\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 3.7373e-06\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.6588e-06\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 3.2368e-06\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 2.9485e-06\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.6240e-06\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 2.5806e-06\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 20ms/sample - loss: 2.6149e-06\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 2.9468e-06\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.1440e-06\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.1842e-06\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.8397e-06\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.7498e-06\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.7446e-06\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.0385e-06\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 22ms/sample - loss: 3.2518e-06\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 3.4758e-06\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 21ms/sample - loss: 3.3409e-06\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.1513e-06\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 2.7629e-06\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.5050e-06\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.2410e-06\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.1356e-06\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 19ms/sample - loss: 2.0636e-06\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/sample - loss: 2.1431e-06\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 2.3130e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.6584e-06\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 2.9839e-06\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.9881e-06\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.6403e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd2b1a64a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.train(epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the model for making predictions with the `predict()` method. The parameter `denormalized` will return values in the original scale of the data. In our case, US dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10338.213, 10472.022, 10549.606, 10594.411, 10846.551, 10608.118,\n",
       "       10969.99 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.predict(denormalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate our model to inspect the statistics for the last epoch of training compared to a single test week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.0, 'rmse': 355.22, 'mape': 2.79}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now save the trained model on disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.save('bitcoin_model_prod_v0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Model()` class can also load a previously trained model when instantiated with the `path` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model(path='bitcoin_model_prod_v0.h5',\n",
    "          data=model_data,\n",
    "          variable='close',\n",
    "          predicted_period_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10338.213, 10472.022, 10549.606, 10594.411, 10846.551, 10608.118,\n",
       "       10969.99 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.predict(denormalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data, Re-train Old Model\n",
    "One strategy discussed earlier regards the re-training of our model with new data. In our case, our biggest concern is to shape data in a way that the model has been configured. As an example, we will configure our model to predict a week using 48 weeks. We will first train the model with the first 48 weeks of 2019, then continue to re-train it over the following weeks until we reach week 58 (i.e 6 the week of the new year 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of full weeks: 58\n"
     ]
    }
   ],
   "source": [
    "print('Number of full weeks: {}'.format(len(model_data) // 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build a model with the first set of data. Notice how we use `7*48 + 7` as the indexer. This is because we use 48 weeks for training and 1 week for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model(data=model_data.loc[0*7:7*48 + 7],\n",
    "          variable='close',\n",
    "          predicted_period_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1dd3078a588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd30cfc550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 for week 48\n",
      "Training model 1 for week 49\n",
      "Training model 2 for week 50\n",
      "Training model 3 for week 51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-bd2d2ce6cc4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training model {0} for week {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Beginning-Application-Development-with-TensorFlow-and-Keras\\Chapter04\\activity_8\\cryptonic\\models\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, epochs, verbose)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             verbose=verbose, shuffle=False)\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\ha20101034\\appdata\\local\\conda\\conda\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Complete the range function and\n",
    "#  the model_data filtering parameters\n",
    "#  using an index to split the data in overlapping\n",
    "#  groups of 7 days. Then, re-train our model\n",
    "#  and collect the results.\n",
    "#\n",
    "#  The variables A, B, C, and D are placeholders.\n",
    "#\n",
    "results = []\n",
    "for i in range(48, 58):\n",
    "    j = i - 48\n",
    "    print(\"Training model {0} for week {1}\".format(j,i))\n",
    "    M.train(model_data.loc[j*7:7*i + 7])\n",
    "    results.append(M.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10341.92 , 10472.677, 10531.48 , 10585.205, 10901.529, 10585.681,\n",
       "       10992.2  ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.predict(denormalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data, New Model\n",
    "Another strategy is to create and train a new model evey time new data is available. This approach tends to reduce catastrophic forgetting, but training time increases as data increases. \n",
    "\n",
    "It's implementation is quite simple.\n",
    "\n",
    "Let's assume we have old data for 49 weeks of 2019 and after a week we now have new data. We represent this wtih the variables `old_data` and `new_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data = model_data.loc[0*7:7*48 + 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = model_data.loc[0*7:7*49 + 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model(data=old_data,\n",
    "          variable='close',\n",
    "          predicted_period_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.build()\n",
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.predict(denormalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, assume that new data is available. Using this technicle we go ahead and create a new model using only the new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Re-instantiate the model with the Model()\n",
    "#  class using the new_data variable instead\n",
    "#  of the old_data one. \n",
    "#\n",
    "\n",
    "M = Model(data=new_data,\n",
    "          variable='close',\n",
    "          predicted_period_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.build()\n",
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.predict(denormalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is very simple to implement and tends to work well. We will be using this to deploy our application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
